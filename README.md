# **Advanced Machine Learning and Deep Learning Projects**
This repository is a showcase of my self-directed learning in machine learning (ML) and deep learning (DL). Through a series of hands-on projects, I have implemented key algorithms and techniques, explored real-world datasets, and applied advanced concepts to solve diverse problems
# Projects Overview
## Week 1 Regression and Data Preparation
* **Linear Regression from Scratch:** Built a basic linear regression model using NumPy, fitted it to a dataset, and plotted the regression line, enhancing understanding of regression fundamentals.
* **Data Cleaning:** Performed missing value imputation, outlier detection/removal, and data normalization/standardization with Pandas to improve data quality.
* **Feature Selection:** Implemented a correlation matrix and mutual information analysis to identify important features and visualized them effectively.
* **Exploratory Data Analysis (EDA):** Conducted EDA using Matplotlib and Seaborn to uncover patterns and generate insightful visualizations.
* **Dimensionality Reduction:** Applied PCA to reduce dataset dimensionality and visualized results in 2D/3D, mastering data compression techniques.

## Week 2  Classifier Algorithms and Performance Analysis
* **K-Nearest Neighbors (K-NN):** Implemented a K-NN classifier from scratch and tested it on the Iris dataset, gaining insights into distance-based classification techniques.
* **Decision Tree Classifier:** Trained and evaluated a decision tree classifier using scikit-learn, visualized the tree structure, and interpreted the decision-making process.
* **Random Forest Classifier:** Built a random forest classifier and optimized its performance using GridSearchCV for hyperparameter tuning, improving model accuracy and robustness.
* **Support Vector Machine (SVM):** Trained an SVM classifier on a complex dataset and visualized its decision boundary, understanding the role of kernels in separating data.
* **Classifier Comparison:** Compared the performance of logistic regression, SVM, and random forest using metrics like accuracy, precision, recall, F1-score, and ROC-AUC, providing a comprehensive evaluation of model effectiveness.

## Week 3: Clustering Techniques and Anomaly Detection
* **K-Means Clustering:** Implemented k-means clustering from scratch, applied it to a dataset, and visualized the resulting clusters to understand partitioning methods.
* **Hierarchical Clustering:** Performed hierarchical clustering, analyzed dendrograms, and determined the optimal number of clusters for better grouping.
* **DBSCAN Algorithm:** Implemented DBSCAN clustering, compared its performance with k-means on a noisy dataset, and observed its effectiveness in handling outliers.
* **Gaussian Mixture Models (GMM):** Applied GMM for clustering, visualized cluster probability distributions, and explored soft clustering techniques.
* **Anomaly Detection:** Built an anomaly detection system using Isolation Forest and Local Outlier Factor (LOF) to identify anomalies in a dataset.

## Week 4: Neural Network Implementation and Optimization
* **Feedforward Neural Network:** Implemented a simple feedforward neural network from scratch using NumPy and trained it on a small dataset, learning the basics of backpropagation and optimization.
* **Deep Neural Network (DNN):** Built a deep neural network using TensorFlow/Keras and trained it on the MNIST dataset for digit classification, achieving high accuracy.
* **Regularization Techniques:** Applied dropout and L2 regularization to neural networks to prevent overfitting, improving generalization on test data.
* **Convolutional Neural Network (CNN):** Designed and trained a CNN on the CIFAR-10 dataset, achieving at least 70% accuracy, and gained experience in handling image classification tasks.

## Week 5: Advanced Machine Learning and Deep Learning Techniques
* **Gradient Boosting Machine (GBM):** Implemented GBM using XGBoost and performed hyperparameter tuning to optimize performance on a dataset.
* **Recurrent Neural Networks (RNN):** Trained an RNN with LSTM/GRU units for time series forecasting, improving accuracy in sequential data prediction.
* **Natural Language Processing (NLP):** Built an NLP pipeline using word embeddings (Word2Vec, GloVe) and RNNs, and trained the model on a sentiment analysis task for effective text classification.
* **Generative Adversarial Network (GAN):** Implemented a GAN to generate synthetic images, trained it on a chosen dataset, and explored the potential of generative models.
R





